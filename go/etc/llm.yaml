base_url: "https://zenmux.ai/api/v1"
api_key: "${ZENMUX_API_KEY}"
# Default model used at runtime. In unit tests you can enable low-cost
# overrides via environment variables without changing this file:
#   - LLM_TEST_MODE=1
#   - LLM_TEST_MODEL or LLM_TEST_MODEL_LIST
default_model: "gpt-5"
timeout: "60s"
max_retries: 3
log_level: "info"

# Note: Zenmux auto-routing is currently unstable. Test mode uses a fixed
# low-cost model (minimax/minimax-m2) instead. This may change in the future.

models:
  gpt-5:
    provider: "openai"
    model_name: "openai/gpt-5"
    temperature: 0.7
    max_completion_tokens: 4096
  claude-sonnet-4.5:
    provider: "anthropic"
    model_name: "anthropic/claude-sonnet-4.5"
    temperature: 0.7
    max_completion_tokens: 4096
  deepseek-chat:
    provider: "deepseek"
    model_name: "deepseek/deepseek-chat-v3.1"
    temperature: 0.6
    max_completion_tokens: 4096
